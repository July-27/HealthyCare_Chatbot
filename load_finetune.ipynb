{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8652c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch==2.1.0+cu118 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (2.1.0+cu118)\n",
      "Requirement already satisfied: torchvision==0.16.0+cu118 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (0.16.0+cu118)\n",
      "Requirement already satisfied: torchaudio==2.1.0 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (2.1.0+cu118)\n",
      "Requirement already satisfied: filelock in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from torch==2.1.0+cu118) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from torch==2.1.0+cu118) (4.13.2)\n",
      "Requirement already satisfied: sympy in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from torch==2.1.0+cu118) (1.14.0)\n",
      "Requirement already satisfied: networkx in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from torch==2.1.0+cu118) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from torch==2.1.0+cu118) (3.1.6)\n",
      "Requirement already satisfied: fsspec in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from torch==2.1.0+cu118) (2025.3.0)\n",
      "Requirement already satisfied: numpy in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from torchvision==0.16.0+cu118) (1.26.4)\n",
      "Requirement already satisfied: requests in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from torchvision==0.16.0+cu118) (2.32.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from torchvision==0.16.0+cu118) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from jinja2->torch==2.1.0+cu118) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from requests->torchvision==0.16.0+cu118) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from requests->torchvision==0.16.0+cu118) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from requests->torchvision==0.16.0+cu118) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from requests->torchvision==0.16.0+cu118) (2025.4.26)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from sympy->torch==2.1.0+cu118) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes==0.41.0 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (0.41.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.36.2\n",
      "  Downloading transformers-4.36.2-py3-none-any.whl.metadata (126 kB)\n",
      "     ---------------------------------------- 0.0/126.8 kB ? eta -:--:--\n",
      "     --- ------------------------------------ 10.2/126.8 kB ? eta -:--:--\n",
      "     ----------- ------------------------- 41.0/126.8 kB 393.8 kB/s eta 0:00:01\n",
      "     ----------------- ------------------- 61.4/126.8 kB 469.7 kB/s eta 0:00:01\n",
      "     ------------------------------- ---- 112.6/126.8 kB 595.3 kB/s eta 0:00:01\n",
      "     ------------------------------------ 126.8/126.8 kB 619.8 kB/s eta 0:00:00\n",
      "Collecting filelock (from transformers==4.36.2)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers==4.36.2)\n",
      "  Downloading huggingface_hub-0.32.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting numpy>=1.17 (from transformers==4.36.2)\n",
      "  Downloading numpy-2.2.6-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
      "     -------------------------- ------------- 41.0/60.8 kB 1.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 60.8/60.8 kB 1.1 MB/s eta 0:00:00\n",
      "Collecting packaging>=20.0 (from transformers==4.36.2)\n",
      "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting pyyaml>=5.1 (from transformers==4.36.2)\n",
      "  Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.36.2)\n",
      "  Downloading regex-2024.11.6-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/41.5 kB ? eta -:--:--\n",
      "     ----------------------------- ---------- 30.7/41.5 kB 1.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- 41.5/41.5 kB 666.1 kB/s eta 0:00:00\n",
      "Collecting requests (from transformers==4.36.2)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers==4.36.2)\n",
      "  Downloading tokenizers-0.15.2-cp311-none-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.3.1 (from transformers==4.36.2)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>=4.27 (from transformers==4.36.2)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.7 kB ? eta -:--:--\n",
      "     ------- -------------------------------- 10.2/57.7 kB ? eta -:--:--\n",
      "     -------------------------------------- 57.7/57.7 kB 752.9 kB/s eta 0:00:00\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.2)\n",
      "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.2)\n",
      "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting colorama (from tqdm>=4.27->transformers==4.36.2)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->transformers==4.36.2)\n",
      "  Downloading charset_normalizer-3.4.2-cp311-cp311-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers==4.36.2)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers==4.36.2)\n",
      "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers==4.36.2)\n",
      "  Downloading certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
      "Downloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
      "   ---------------------------------------- 0.0/8.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/8.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/8.2 MB 960.0 kB/s eta 0:00:09\n",
      "   ---------------------------------------- 0.1/8.2 MB 975.2 kB/s eta 0:00:09\n",
      "    --------------------------------------- 0.1/8.2 MB 819.2 kB/s eta 0:00:10\n",
      "    --------------------------------------- 0.2/8.2 MB 833.5 kB/s eta 0:00:10\n",
      "    --------------------------------------- 0.2/8.2 MB 794.9 kB/s eta 0:00:11\n",
      "   - -------------------------------------- 0.2/8.2 MB 769.9 kB/s eta 0:00:11\n",
      "   - -------------------------------------- 0.2/8.2 MB 793.0 kB/s eta 0:00:11\n",
      "   - -------------------------------------- 0.3/8.2 MB 764.6 kB/s eta 0:00:11\n",
      "   - -------------------------------------- 0.3/8.2 MB 780.0 kB/s eta 0:00:11\n",
      "   - -------------------------------------- 0.4/8.2 MB 813.8 kB/s eta 0:00:10\n",
      "   - -------------------------------------- 0.4/8.2 MB 798.7 kB/s eta 0:00:10\n",
      "   -- ------------------------------------- 0.5/8.2 MB 823.7 kB/s eta 0:00:10\n",
      "   -- ------------------------------------- 0.5/8.2 MB 832.7 kB/s eta 0:00:10\n",
      "   -- ------------------------------------- 0.5/8.2 MB 852.0 kB/s eta 0:00:10\n",
      "   -- ------------------------------------- 0.6/8.2 MB 848.4 kB/s eta 0:00:09\n",
      "   --- ------------------------------------ 0.6/8.2 MB 863.8 kB/s eta 0:00:09\n",
      "   --- ------------------------------------ 0.7/8.2 MB 864.2 kB/s eta 0:00:09\n",
      "   --- ------------------------------------ 0.7/8.2 MB 878.1 kB/s eta 0:00:09\n",
      "   --- ------------------------------------ 0.8/8.2 MB 881.1 kB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 0.8/8.2 MB 899.6 kB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 0.9/8.2 MB 908.8 kB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 0.9/8.2 MB 907.1 kB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.0/8.2 MB 915.1 kB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 1.0/8.2 MB 922.5 kB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 1.1/8.2 MB 938.1 kB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 1.1/8.2 MB 936.3 kB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 1.2/8.2 MB 961.8 kB/s eta 0:00:08\n",
      "   ------ --------------------------------- 1.2/8.2 MB 966.5 kB/s eta 0:00:08\n",
      "   ------ --------------------------------- 1.3/8.2 MB 967.6 kB/s eta 0:00:08\n",
      "   ------ --------------------------------- 1.4/8.2 MB 986.5 kB/s eta 0:00:07\n",
      "   ------ --------------------------------- 1.4/8.2 MB 1.0 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 1.5/8.2 MB 1.0 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 1.6/8.2 MB 1.0 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 1.6/8.2 MB 1.0 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 1.7/8.2 MB 1.0 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 1.8/8.2 MB 1.1 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 1.8/8.2 MB 1.1 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 1.9/8.2 MB 1.1 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 2.0/8.2 MB 1.1 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 2.0/8.2 MB 1.1 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 2.1/8.2 MB 1.1 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 2.2/8.2 MB 1.1 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 2.3/8.2 MB 1.2 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 2.4/8.2 MB 1.2 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 2.5/8.2 MB 1.2 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 2.5/8.2 MB 1.2 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 2.6/8.2 MB 1.2 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 2.7/8.2 MB 1.2 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 2.8/8.2 MB 1.2 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 2.9/8.2 MB 1.3 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 3.0/8.2 MB 1.3 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 3.1/8.2 MB 1.3 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 3.2/8.2 MB 1.3 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 3.3/8.2 MB 1.3 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 3.4/8.2 MB 1.3 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 3.5/8.2 MB 1.4 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 3.6/8.2 MB 1.4 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 3.8/8.2 MB 1.4 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 3.9/8.2 MB 1.4 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 4.0/8.2 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 4.1/8.2 MB 1.5 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 4.2/8.2 MB 1.5 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 4.4/8.2 MB 1.5 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 4.5/8.2 MB 1.5 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 4.6/8.2 MB 1.5 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 4.7/8.2 MB 1.5 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 4.9/8.2 MB 1.6 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 5.0/8.2 MB 1.6 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 5.1/8.2 MB 1.6 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 5.3/8.2 MB 1.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 5.4/8.2 MB 1.7 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 5.6/8.2 MB 1.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 5.8/8.2 MB 1.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 5.9/8.2 MB 1.7 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 6.1/8.2 MB 1.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 6.2/8.2 MB 1.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 6.4/8.2 MB 1.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 6.6/8.2 MB 1.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 6.7/8.2 MB 1.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 6.9/8.2 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.1/8.2 MB 1.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.3/8.2 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.5/8.2 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 7.7/8.2 MB 2.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 7.9/8.2 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.1/8.2 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.2/8.2 MB 2.1 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.32.1-py3-none-any.whl (509 kB)\n",
      "   ---------------------------------------- 0.0/509.4 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 204.8/509.4 kB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 440.3/509.4 kB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 509.4/509.4 kB 4.5 MB/s eta 0:00:00\n",
      "Downloading numpy-2.2.6-cp311-cp311-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/12.9 MB 6.9 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.5/12.9 MB 5.9 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.7/12.9 MB 5.7 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.9/12.9 MB 5.4 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 1.2/12.9 MB 5.5 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.5/12.9 MB 5.5 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.8/12.9 MB 5.6 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 2.1/12.9 MB 5.7 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.3/12.9 MB 5.7 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.6/12.9 MB 5.7 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.9/12.9 MB 5.8 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.2/12.9 MB 5.9 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.5/12.9 MB 5.9 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.9/12.9 MB 6.0 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 4.2/12.9 MB 6.1 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.6/12.9 MB 6.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.9/12.9 MB 6.3 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 5.2/12.9 MB 6.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.6/12.9 MB 6.5 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 6.0/12.9 MB 6.6 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 6.3/12.9 MB 6.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 6.8/12.9 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 7.2/12.9 MB 6.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.6/12.9 MB 6.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 8.0/12.9 MB 7.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 8.4/12.9 MB 7.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.9/12.9 MB 7.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.4/12.9 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.8/12.9 MB 7.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.3/12.9 MB 7.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.9/12.9 MB 7.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.4/12.9 MB 8.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.9/12.9 MB 8.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.4/12.9 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 9.0 MB/s eta 0:00:00\n",
      "Downloading packaging-25.0-py3-none-any.whl (66 kB)\n",
      "   ---------------------------------------- 0.0/66.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 66.5/66.5 kB 1.2 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl (161 kB)\n",
      "   ---------------------------------------- 0.0/162.0 kB ? eta -:--:--\n",
      "   ------------------------------------- -- 153.6/162.0 kB 9.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 162.0/162.0 kB 3.2 MB/s eta 0:00:00\n",
      "Downloading regex-2024.11.6-cp311-cp311-win_amd64.whl (274 kB)\n",
      "   ---------------------------------------- 0.0/274.1 kB ? eta -:--:--\n",
      "   ------------------------------------- -- 256.0/274.1 kB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 274.1/274.1 kB 4.2 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "   ---------------------------------------- 0.0/308.9 kB ? eta -:--:--\n",
      "   ------------------------------------ -- 286.7/308.9 kB 17.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 308.9/308.9 kB 6.4 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.15.2-cp311-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.2 MB 11.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.1/2.2 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.7/2.2 MB 12.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 11.6 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.5 kB ? eta -:--:--\n",
      "   ------------------------------- -------- 61.4/78.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.5/78.5 kB 1.5 MB/s eta 0:00:00\n",
      "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "   ---------------------------------------- 0.0/64.9 kB ? eta -:--:--\n",
      "   ------------------------------------- -- 61.4/64.9 kB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 64.9/64.9 kB 868.1 kB/s eta 0:00:00\n",
      "Downloading certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
      "   ---------------------------------------- 0.0/159.6 kB ? eta -:--:--\n",
      "   ----------------------------------- ---- 143.4/159.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 159.6/159.6 kB 2.4 MB/s eta 0:00:00\n",
      "Downloading charset_normalizer-3.4.2-cp311-cp311-win_amd64.whl (105 kB)\n",
      "   ---------------------------------------- 0.0/105.4 kB ? eta -:--:--\n",
      "   ---------------------------------- ----- 92.2/105.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 105.4/105.4 kB 1.5 MB/s eta 0:00:00\n",
      "Downloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "   ---------------------------------------- 0.0/199.1 kB ? eta -:--:--\n",
      "   ------------------------------------ -- 184.3/199.1 kB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 199.1/199.1 kB 3.0 MB/s eta 0:00:00\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "   ---------------------------------------- 0.0/70.4 kB ? eta -:--:--\n",
      "   ---------------------------------- ----- 61.4/70.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 70.4/70.4 kB 1.3 MB/s eta 0:00:00\n",
      "Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "   ---------------------------------------- 0.0/45.8 kB ? eta -:--:--\n",
      "   -------------------------- ------------- 30.7/45.8 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 45.8/45.8 kB 564.5 kB/s eta 0:00:00\n",
      "Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "   ---------------------------------------- 0.0/128.7 kB ? eta -:--:--\n",
      "   ----------------------------------- ---- 112.6/128.7 kB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 128.7/128.7 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Installing collected packages: urllib3, typing-extensions, safetensors, regex, pyyaml, packaging, numpy, idna, fsspec, filelock, colorama, charset-normalizer, certifi, tqdm, requests, huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.4.0\n",
      "    Uninstalling urllib3-2.4.0:\n",
      "      Successfully uninstalled urllib3-2.4.0\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.13.2\n",
      "    Uninstalling typing_extensions-4.13.2:\n",
      "      Successfully uninstalled typing_extensions-4.13.2\n",
      "  Attempting uninstall: safetensors\n",
      "    Found existing installation: safetensors 0.5.3\n",
      "    Uninstalling safetensors-0.5.3:\n",
      "      Successfully uninstalled safetensors-0.5.3\n",
      "  Attempting uninstall: regex\n",
      "    Found existing installation: regex 2024.11.6\n",
      "    Uninstalling regex-2024.11.6:\n",
      "      Successfully uninstalled regex-2024.11.6\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 6.0.2\n",
      "    Uninstalling PyYAML-6.0.2:\n",
      "      Successfully uninstalled PyYAML-6.0.2\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 25.0\n",
      "    Uninstalling packaging-25.0:\n",
      "      Successfully uninstalled packaging-25.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.10\n",
      "    Uninstalling idna-3.10:\n",
      "      Successfully uninstalled idna-3.10\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.0\n",
      "    Uninstalling fsspec-2025.3.0:\n",
      "      Successfully uninstalled fsspec-2025.3.0\n",
      "  Attempting uninstall: filelock\n",
      "    Found existing installation: filelock 3.18.0\n",
      "    Uninstalling filelock-3.18.0:\n",
      "      Successfully uninstalled filelock-3.18.0\n",
      "  Attempting uninstall: colorama\n",
      "    Found existing installation: colorama 0.4.6\n",
      "    Uninstalling colorama-0.4.6:\n",
      "      Successfully uninstalled colorama-0.4.6\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 3.4.2\n",
      "    Uninstalling charset-normalizer-3.4.2:\n",
      "      Successfully uninstalled charset-normalizer-3.4.2\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2025.4.26\n",
      "    Uninstalling certifi-2025.4.26:\n",
      "      Successfully uninstalled certifi-2025.4.26\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.67.1\n",
      "    Uninstalling tqdm-4.67.1:\n",
      "      Successfully uninstalled tqdm-4.67.1\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.32.3\n",
      "    Uninstalling requests-2.32.3:\n",
      "      Successfully uninstalled requests-2.32.3\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.31.4\n",
      "    Uninstalling huggingface-hub-0.31.4:\n",
      "      Successfully uninstalled huggingface-hub-0.31.4\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.15.2\n",
      "    Uninstalling tokenizers-0.15.2:\n",
      "      Successfully uninstalled tokenizers-0.15.2\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.36.2\n",
      "    Uninstalling transformers-4.36.2:\n",
      "      Successfully uninstalled transformers-4.36.2\n",
      "Successfully installed certifi-2025.4.26 charset-normalizer-3.4.2 colorama-0.4.6 filelock-3.18.0 fsspec-2025.5.1 huggingface-hub-0.32.1 idna-3.10 numpy-2.2.6 packaging-25.0 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.3 safetensors-0.5.3 tokenizers-0.15.2 tqdm-4.67.1 transformers-4.36.2 typing-extensions-4.13.2 urllib3-2.4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: trl==0.7.1 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (0.7.1)\n",
      "Requirement already satisfied: torch>=1.4.0 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from trl==0.7.1) (2.1.0+cu118)\n",
      "Requirement already satisfied: transformers>=4.18.0 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from trl==0.7.1) (4.36.2)\n",
      "Requirement already satisfied: numpy>=1.18.2 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from trl==0.7.1) (2.2.6)\n",
      "Requirement already satisfied: accelerate in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from trl==0.7.1) (0.26.1)\n",
      "Requirement already satisfied: datasets in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from trl==0.7.1) (3.6.0)\n",
      "Requirement already satisfied: filelock in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from torch>=1.4.0->trl==0.7.1) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from torch>=1.4.0->trl==0.7.1) (4.13.2)\n",
      "Requirement already satisfied: sympy in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from torch>=1.4.0->trl==0.7.1) (1.14.0)\n",
      "Requirement already satisfied: networkx in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from torch>=1.4.0->trl==0.7.1) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from torch>=1.4.0->trl==0.7.1) (3.1.6)\n",
      "Requirement already satisfied: fsspec in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from torch>=1.4.0->trl==0.7.1) (2025.5.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from transformers>=4.18.0->trl==0.7.1) (0.32.1)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from transformers>=4.18.0->trl==0.7.1) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from transformers>=4.18.0->trl==0.7.1) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from transformers>=4.18.0->trl==0.7.1) (2024.11.6)\n",
      "Requirement already satisfied: requests in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from transformers>=4.18.0->trl==0.7.1) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from transformers>=4.18.0->trl==0.7.1) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from transformers>=4.18.0->trl==0.7.1) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from transformers>=4.18.0->trl==0.7.1) (4.67.1)\n",
      "Requirement already satisfied: psutil in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from accelerate->trl==0.7.1) (7.0.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from datasets->trl==0.7.1) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from datasets->trl==0.7.1) (0.3.8)\n",
      "Requirement already satisfied: pandas in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from datasets->trl==0.7.1) (2.2.3)\n",
      "Requirement already satisfied: xxhash in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from datasets->trl==0.7.1) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from datasets->trl==0.7.1) (0.70.16)\n",
      "Collecting fsspec (from torch>=1.4.0->trl==0.7.1)\n",
      "  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.7.1) (3.11.18)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from requests->transformers>=4.18.0->trl==0.7.1) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from requests->transformers>=4.18.0->trl==0.7.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from requests->transformers>=4.18.0->trl==0.7.1) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from requests->transformers>=4.18.0->trl==0.7.1) (2025.4.26)\n",
      "Requirement already satisfied: colorama in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from tqdm>=4.27->transformers>=4.18.0->trl==0.7.1) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from jinja2->torch>=1.4.0->trl==0.7.1) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from pandas->datasets->trl==0.7.1) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from pandas->datasets->trl==0.7.1) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from pandas->datasets->trl==0.7.1) (2025.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from sympy->torch>=1.4.0->trl==0.7.1) (1.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.7.1) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.7.1) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.7.1) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.7.1) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.7.1) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.7.1) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.7.1) (1.20.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.7.1) (1.17.0)\n",
      "Using cached fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Installing collected packages: fsspec\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.5.1\n",
      "    Uninstalling fsspec-2025.5.1:\n",
      "      Successfully uninstalled fsspec-2025.5.1\n",
      "Successfully installed fsspec-2025.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: peft==0.7.1 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (0.7.1)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from peft==0.7.1) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from peft==0.7.1) (25.0)\n",
      "Requirement already satisfied: psutil in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from peft==0.7.1) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from peft==0.7.1) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from peft==0.7.1) (2.1.0+cu118)\n",
      "Requirement already satisfied: transformers in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from peft==0.7.1) (4.36.2)\n",
      "Requirement already satisfied: tqdm in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from peft==0.7.1) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from peft==0.7.1) (0.26.1)\n",
      "Requirement already satisfied: safetensors in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from peft==0.7.1) (0.5.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from peft==0.7.1) (0.32.1)\n",
      "Requirement already satisfied: filelock in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from huggingface-hub>=0.17.0->peft==0.7.1) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from huggingface-hub>=0.17.0->peft==0.7.1) (2025.3.0)\n",
      "Requirement already satisfied: requests in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from huggingface-hub>=0.17.0->peft==0.7.1) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from huggingface-hub>=0.17.0->peft==0.7.1) (4.13.2)\n",
      "Requirement already satisfied: sympy in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from torch>=1.13.0->peft==0.7.1) (1.14.0)\n",
      "Requirement already satisfied: networkx in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from torch>=1.13.0->peft==0.7.1) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from torch>=1.13.0->peft==0.7.1) (3.1.6)\n",
      "Requirement already satisfied: colorama in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from tqdm->peft==0.7.1) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from transformers->peft==0.7.1) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from transformers->peft==0.7.1) (0.15.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from jinja2->torch>=1.13.0->peft==0.7.1) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.1) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.1) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.1) (2025.4.26)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from sympy->torch>=1.13.0->peft==0.7.1) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate==0.26.1 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (0.26.1)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from accelerate==0.26.1) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from accelerate==0.26.1) (25.0)\n",
      "Requirement already satisfied: psutil in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from accelerate==0.26.1) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from accelerate==0.26.1) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from accelerate==0.26.1) (2.1.0+cu118)\n",
      "Requirement already satisfied: huggingface-hub in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from accelerate==0.26.1) (0.32.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from accelerate==0.26.1) (0.5.3)\n",
      "Requirement already satisfied: filelock in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from torch>=1.10.0->accelerate==0.26.1) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from torch>=1.10.0->accelerate==0.26.1) (4.13.2)\n",
      "Requirement already satisfied: sympy in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from torch>=1.10.0->accelerate==0.26.1) (1.14.0)\n",
      "Requirement already satisfied: networkx in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from torch>=1.10.0->accelerate==0.26.1) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from torch>=1.10.0->accelerate==0.26.1) (3.1.6)\n",
      "Requirement already satisfied: fsspec in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from torch>=1.10.0->accelerate==0.26.1) (2025.3.0)\n",
      "Requirement already satisfied: requests in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from huggingface-hub->accelerate==0.26.1) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from huggingface-hub->accelerate==0.26.1) (4.67.1)\n",
      "Requirement already satisfied: colorama in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate==0.26.1) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate==0.26.1) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from requests->huggingface-hub->accelerate==0.26.1) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from requests->huggingface-hub->accelerate==0.26.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from requests->huggingface-hub->accelerate==0.26.1) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from requests->huggingface-hub->accelerate==0.26.1) (2025.4.26)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate==0.26.1) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (3.6.0)\n",
      "Requirement already satisfied: filelock in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from datasets) (2.2.6)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from datasets) (0.32.1)\n",
      "Requirement already satisfied: packaging in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.18)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
      "Requirement already satisfied: colorama in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\ai17c\\capstone ai17c\\lora_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.1.0+cu118 torchvision==0.16.0+cu118 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install bitsandbytes==0.41.0\n",
    "\n",
    "\n",
    "# Ci transformers, trl, peft, accelerate\n",
    "!pip install transformers==4.36.2 --force-reinstall --no-cache-dir\n",
    "!pip install trl==0.7.1\n",
    "!pip install peft==0.7.1\n",
    "!pip install accelerate==0.26.1\n",
    "!pip install datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7636a768-331e-43e6-b864-9eadc11e0e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: triton 3.3.0\n",
      "Uninstalling triton-3.3.0:\n",
      "  Successfully uninstalled triton-3.3.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/mnt/d/AI17C/Capstone AI17C/venv/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement triton==2.1.0 (from versions: 2.2.0, 2.3.0, 2.3.1, 3.0.0, 3.1.0, 3.2.0, 3.3.0)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for triton==2.1.0\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y triton\n",
    "!pip install triton==2.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85b29d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AI17C\\Capstone AI17C\\lora_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.1.0+cu118\n",
      "transformers: 4.36.2\n",
      "trl: 0.7.1\n",
      "peft: 0.7.1\n",
      "CUDA: True\n"
     ]
    }
   ],
   "source": [
    "import torch, transformers, trl, peft\n",
    "\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"transformers:\", transformers.__version__)\n",
    "print(\"trl:\", trl.__version__)\n",
    "print(\"peft:\", peft.__version__)\n",
    "print(\"CUDA:\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1de6a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig,\n",
    "    HfArgumentParser, TrainingArguments, pipeline, logging\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aad0cd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "input_file = 'medquad_dataset.jsonl'\n",
    "output_file = 'medquad_llama_chat_format.jsonl'\n",
    "\n",
    "with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
    "    for line in infile:\n",
    "        item = json.loads(line)\n",
    "        question = item['question'].strip().replace('\\n', ' ')\n",
    "        answer = item['answer'].strip().replace('\\n', ' ')\n",
    "        llama_chat_format = f\"<s>[INST] {question} [/INST] {answer} </s>\"\n",
    "        outfile.write(json.dumps({\"text\": llama_chat_format}) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d7c939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# c d liu gc\n",
    "with open('medquad_llama_chat_format.jsonl', 'r') as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "# Xo trn d liu\n",
    "random.seed(42)\n",
    "random.shuffle(data)\n",
    "\n",
    "# Chia theo t l 80% train, 10% valid, 10% test\n",
    "n_total = len(data)\n",
    "n_train = int(0.9 * n_total)\n",
    "\n",
    "train_data = data[:n_train]\n",
    "valid_data = data[n_train:]\n",
    "\n",
    "# Ghi ra file\n",
    "with open('train.jsonl', 'w') as f:\n",
    "    for item in train_data:\n",
    "        f.write(json.dumps(item) + '\\n')\n",
    "\n",
    "with open('valid.jsonl', 'w') as f:\n",
    "    for item in valid_data:\n",
    "        f.write(json.dumps(item) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64434a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_name = 'NousResearch/Llama-2-7b-chat-hf'\n",
    "finetune_model_name='my_model_finetune_llama2_7b'\n",
    "\n",
    "output_dir = './results'\n",
    "\n",
    "no_of_epochs = 1\n",
    "\n",
    "# No change params\n",
    "use_4bit, bnb_4bit_compute_dtype, bnb_4bit_quant_type, use_nested_quant = True, \"int4\", \"nf4\", False # To quantization\n",
    "lora_r, lora_alpha, lora_dropout = 64, 16, 0.1\n",
    "fp16, bf16 =  False, False\n",
    "per_device_train_batch_size, per_device_eval_batch_size = 4, 4\n",
    "gradient_accumulation_steps, gradient_checkpointing, max_grad_norm = 1, True, 0.3\n",
    "learning_rate, weight_decay, optim = 2e-4, 0.001, \"paged_adamw_32bit\"\n",
    "lr_scheduler_type, max_steps, warmup_ratio = \"cosine\", -1, 0.03\n",
    "group_by_length, save_steps, logging_steps = True, 0, 25\n",
    "max_seq_length, packing, device_map = None, False, {\"\": 0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ed3bfc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/AI17C/Capstone AI17C/venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.integrations.bitsandbytes because of the following error (look up to see its traceback):\nNo module named 'triton.ops'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/AI17C/Capstone AI17C/venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:1382\u001b[39m, in \u001b[36m_LazyModule._get_module\u001b[39m\u001b[34m(self, module_name)\u001b[39m\n\u001b[32m   1381\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1382\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1383\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/importlib/__init__.py:90\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     89\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1387\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1331\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:935\u001b[39m, in \u001b[36m_load_unlocked\u001b[39m\u001b[34m(spec)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:995\u001b[39m, in \u001b[36mexec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:488\u001b[39m, in \u001b[36m_call_with_frames_removed\u001b[39m\u001b[34m(f, *args, **kwds)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/AI17C/Capstone AI17C/venv/lib/python3.12/site-packages/transformers/integrations/bitsandbytes.py:11\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_bitsandbytes_available():\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbitsandbytes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbnb\u001b[39;00m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/AI17C/Capstone AI17C/venv/lib/python3.12/site-packages/bitsandbytes/__init__.py:16\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcextension\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m COMPILED_WITH_CUDA\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m modules\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m COMPILED_WITH_CUDA:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/AI17C/Capstone AI17C/venv/lib/python3.12/site-packages/bitsandbytes/nn/__init__.py:6\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodules\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Int8Params, Linear8bitLt, StableEmbedding, Linear4bit, LinearNF4, LinearFP4, Params4bit, OutlierAwareLinear, SwitchBackLinearBnb\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtriton_based_modules\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SwitchBackLinear, SwitchBackLinearGlobal, SwitchBackLinearVectorwise, StandardLinear\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/AI17C/Capstone AI17C/venv/lib/python3.12/site-packages/bitsandbytes/nn/triton_based_modules.py:8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbitsandbytes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtriton\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtriton_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_triton_available\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbitsandbytes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtriton\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdequantize_rowwise\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dequantize_rowwise\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbitsandbytes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtriton\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantize_rowwise\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m quantize_rowwise\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/AI17C/Capstone AI17C/venv/lib/python3.12/site-packages/bitsandbytes/triton/dequantize_rowwise.py:12\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtriton\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlanguage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtl\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtriton\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmatmul_perf_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m early_config_prune, estimate_matmul_time\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# rowwise quantize\u001b[39;00m\n\u001b[32m     15\u001b[39m \n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# TODO: autotune this better.\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'triton.ops'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      6\u001b[39m bnb_config = BitsAndBytesConfig(\n\u001b[32m      7\u001b[39m     load_in_4bit=use_4bit,\n\u001b[32m      8\u001b[39m     bnb_4bit_quant_type=bnb_4bit_quant_type,\n\u001b[32m      9\u001b[39m     bnb_4bit_compute_dtype=compute_dtype,\n\u001b[32m     10\u001b[39m     bnb_4bit_use_double_quant=use_nested_quant,\n\u001b[32m     11\u001b[39m )\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Load base model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m model = \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbnb_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m model.config.use_cache = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     21\u001b[39m model.config.pretraining_tp = \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/AI17C/Capstone AI17C/venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:566\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    564\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._model_mapping.keys():\n\u001b[32m    565\u001b[39m     model_class = _get_model_class(config, \u001b[38;5;28mcls\u001b[39m._model_mapping)\n\u001b[32m--> \u001b[39m\u001b[32m566\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    568\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    569\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    570\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    571\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    572\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/AI17C/Capstone AI17C/venv/lib/python3.12/site-packages/transformers/modeling_utils.py:3476\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[39m\n\u001b[32m   3473\u001b[39m     keep_in_fp32_modules = []\n\u001b[32m   3475\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m load_in_8bit \u001b[38;5;129;01mor\u001b[39;00m load_in_4bit:\n\u001b[32m-> \u001b[39m\u001b[32m3476\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mintegrations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_keys_to_not_convert, replace_with_bnb_linear\n\u001b[32m   3478\u001b[39m     llm_int8_skip_modules = quantization_config.llm_int8_skip_modules\n\u001b[32m   3479\u001b[39m     load_in_8bit_fp32_cpu_offload = quantization_config.llm_int8_enable_fp32_cpu_offload\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1412\u001b[39m, in \u001b[36m_handle_fromlist\u001b[39m\u001b[34m(module, fromlist, import_, recursive)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/AI17C/Capstone AI17C/venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:1372\u001b[39m, in \u001b[36m_LazyModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1370\u001b[39m     value = \u001b[38;5;28mself\u001b[39m._get_module(name)\n\u001b[32m   1371\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._class_to_module.keys():\n\u001b[32m-> \u001b[39m\u001b[32m1372\u001b[39m     module = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1373\u001b[39m     value = \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[32m   1374\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/AI17C/Capstone AI17C/venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:1384\u001b[39m, in \u001b[36m_LazyModule._get_module\u001b[39m\u001b[34m(self, module_name)\u001b[39m\n\u001b[32m   1382\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib.import_module(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m + module_name, \u001b[38;5;28mself\u001b[39m.\u001b[34m__name__\u001b[39m)\n\u001b[32m   1383\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1384\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1385\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m because of the following error (look up to see its\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1386\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1387\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: Failed to import transformers.integrations.bitsandbytes because of the following error (look up to see its traceback):\nNo module named 'triton.ops'"
     ]
    }
   ],
   "source": [
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")\n",
    "\n",
    "# Load base model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=device_map\n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "# Load LLaMA tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\" # Fix weird overflow issue with fp16 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee329b00",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_train_epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 14\u001b[0m\n\u001b[0;32m      2\u001b[0m peft_config \u001b[38;5;241m=\u001b[39m LoraConfig(\n\u001b[0;32m      3\u001b[0m     r\u001b[38;5;241m=\u001b[39mlora_r,\n\u001b[0;32m      4\u001b[0m     lora_alpha\u001b[38;5;241m=\u001b[39mlora_alpha,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m     task_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCAUSAL_LM\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Set training parameters\u001b[39;00m\n\u001b[0;32m     12\u001b[0m training_guments \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[0;32m     13\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39moutput_dir,\n\u001b[1;32m---> 14\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39mnum_train_epochs, \n\u001b[0;32m     15\u001b[0m     per_device_train_batch_size\u001b[38;5;241m=\u001b[39mper_device_train_batch_size,\n\u001b[0;32m     16\u001b[0m     gradient_accumulation_steps\u001b[38;5;241m=\u001b[39mgradient_accumulation_steps,\n\u001b[0;32m     17\u001b[0m     optim\u001b[38;5;241m=\u001b[39moptim,\n\u001b[0;32m     18\u001b[0m     save_steps\u001b[38;5;241m=\u001b[39msave_steps,\n\u001b[0;32m     19\u001b[0m     logging_steps\u001b[38;5;241m=\u001b[39mlogging_steps,\n\u001b[0;32m     20\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate,\n\u001b[0;32m     21\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[0;32m     22\u001b[0m     fp16\u001b[38;5;241m=\u001b[39mfp16,\n\u001b[0;32m     23\u001b[0m     bf16\u001b[38;5;241m=\u001b[39mbf16,\n\u001b[0;32m     24\u001b[0m     max_grad_norm\u001b[38;5;241m=\u001b[39mmax_grad_norm,\n\u001b[0;32m     25\u001b[0m     max_steps\u001b[38;5;241m=\u001b[39mmax_steps,\n\u001b[0;32m     26\u001b[0m     warmup_ratio\u001b[38;5;241m=\u001b[39mwarmup_ratio,\n\u001b[0;32m     27\u001b[0m     group_by_length\u001b[38;5;241m=\u001b[39mgroup_by_length,\n\u001b[0;32m     28\u001b[0m     lr_scheduler_type\u001b[38;5;241m=\u001b[39mlr_scheduler_type\n\u001b[0;32m     29\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num_train_epochs' is not defined"
     ]
    }
   ],
   "source": [
    "# Cu hnh LoRA\n",
    "peft_config = LoraConfig(\n",
    "    r=lora_r,\n",
    "    lora_alpha=lora_alpha,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=lora_dropout,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "# Set training parameters\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs= no_of_epochs, \n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    optim=optim,\n",
    "    save_steps=save_steps,\n",
    "    logging_steps=logging_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    fp16=fp16,\n",
    "    bf16=bf16,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    max_steps=max_steps,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    group_by_length=group_by_length,\n",
    "    lr_scheduler_type=lr_scheduler_type\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd64cb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=load_dataset('json', data_files='train.jsonl', split='train'),\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=packing,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lora_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
